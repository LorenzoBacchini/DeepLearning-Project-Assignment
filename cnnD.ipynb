{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b876e863",
   "metadata": {},
   "source": [
    "# LeNet-5 \n",
    "cnn architecture to classify numbers from 0 to 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53b3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3477112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d72426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Tanh()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Tanh()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=3072, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=2048, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (fc4): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN to classify the images\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # first convolutional block\n",
    "        # initial size = 3x32x32\n",
    "        self.conv_block1 = nn.Sequential(nn.Conv2d(in_channels= 3, out_channels=32, kernel_size=5, stride=1, padding=2), #32x32x32 [(Wâˆ’K+2P)/S]+1\n",
    "                                         nn.Tanh(),\n",
    "                                         nn.MaxPool2d(2, 2)) #32x16x16\n",
    "        # second convolutional block\n",
    "        self.conv_block2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2), #64x16x16\n",
    "                                         nn.Tanh(),\n",
    "                                         nn.MaxPool2d(2, 2)) #64x8x8\n",
    "        # fully connected blocks\n",
    "        self.fc1 = nn.Flatten(1)\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64 * 8 * 8, 3072),\n",
    "                                nn.Tanh())\n",
    "        self.fc3 = nn.Sequential(nn.Linear(3072, 2048),\n",
    "                                 nn.Tanh())\n",
    "        self.fc4 = nn.Linear(2048, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = LeNet5().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b31438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Loss and Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5467dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicDMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, root=\"./data\", train=True, min_digits=1, max_digits=3, dataset_size=500000, transform=None, download=True):\n",
    "        super().__init__(root=root, train=train, transform=transform, download=download)\n",
    "\n",
    "        self.min_digits = min_digits\n",
    "        self.max_digits = max_digits\n",
    "        self.dataset_size = dataset_size\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_to_indices = {\n",
    "            i: torch.where(self.targets == i)[0] for i in range(10)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        n_digits = random.randint(self.min_digits,self.max_digits)\n",
    "        number = random.randint(0 if n_digits == 1 else 10**(n_digits-1), 10**n_digits - 1)\n",
    "        digits = list(str(number))\n",
    "\n",
    "        digit_images = []\n",
    "        for d in digits:\n",
    "            label = int(d)\n",
    "            indices = self.label_to_indices[label]\n",
    "            chosen_idx = indices[torch.randint(len(indices), (1,)).item()]\n",
    "            img = self.data[chosen_idx]\n",
    "            img = img.unsqueeze(0)\n",
    "            digit_images.append(img)\n",
    "        for i in range(n_digits, self.max_digits):\n",
    "            img = torch.zeros((28, 28))\n",
    "            img = img.unsqueeze(0)\n",
    "            digit_images.append(img)\n",
    "        concat_img = torch.cat(digit_images, dim=0)\n",
    "\n",
    "        if self.transform:\n",
    "            concat_img = self.transform(concat_img)\n",
    "\n",
    "        return concat_img, number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72acb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_mean = 0.1307\n",
    "mnist_std = 0.3081\n",
    "\n",
    "batch_size_train = 64\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mnist_mean, mnist_std)\n",
    "])\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "def denormalize_train(img):\n",
    "    img = img * mnist_std\n",
    "    return img + mnist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37ff13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d_dataset = DynamicDMNIST(transform=transform_train)\n",
    "train_d_dataloader = torch.utils.data.DataLoader(\n",
    "    train_d_dataset,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN!\n",
    "# put net into train mode\n",
    "net.train()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_d_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b405b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to save the model\n",
    "PATH = './res/LeNet5_2.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c40748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to load the model\n",
    "PATH = './res/LeNet5_2.pth'\n",
    "net.load_state_dict(torch.load(PATH, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b75490",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformW = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32,32)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mnist_mean, mnist_std)\n",
    "])\n",
    "\n",
    "def denormalizeD(img):\n",
    "    img = img * mnist_std\n",
    "    return img + mnist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6547482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class testMNISTDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        # leggo le cartelle e ordino numericamente\n",
    "        classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))], key=int)\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        \n",
    "        # creo lista (path_file, label)\n",
    "        for cls_name in classes:\n",
    "            cls_idx = self.class_to_idx[cls_name]\n",
    "            folder_path = os.path.join(root, cls_name)\n",
    "            files = sorted(os.listdir(folder_path), key = lambda x: int(x.removesuffix('.png')))\n",
    "            for fname in files:\n",
    "                self.samples.append((os.path.join(folder_path, fname), cls_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6445ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDMNIST = testMNISTDataset('./data/testDMNIST1/', transformW)\n",
    "\n",
    "test_dataloaderD = DataLoader(testDMNIST, # dataset to iterate\n",
    "                              batch_size=1000, # how many images to load every iteration\n",
    "                              shuffle=False) # sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b1ad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "Accuracy of the network on the 45330 test images: 73 %\n"
     ]
    }
   ],
   "source": [
    "# now lets evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# put net into evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloaderD):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "err = 0\n",
    "# put net into evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloaderD):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for p, l in zip(predicted, labels):\n",
    "            if p != l:\n",
    "                err += 1\n",
    "                print(f'predicted: {p} label = {l}')\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')\n",
    "print(f'err: {err}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
