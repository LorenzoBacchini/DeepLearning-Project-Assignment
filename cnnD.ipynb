{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b876e863",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "cnn architecture to classify numbers from 0 to 999\n",
    "\n",
    "this classifier uses a datase made of concatenated images on the channel axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b5b48f",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d72426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # first convolutional block\n",
    "        # initial size = 1x32x32\n",
    "        self.conv_block1 = nn.Sequential(nn.Conv2d(in_channels= 3, out_channels=32, kernel_size=5, stride=1, padding=2), #32x32x32 [(Wâˆ’K+2P)/S]+1\n",
    "                                         nn.BatchNorm2d(32),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, 2)) #32x16x16\n",
    "        # second convolutional block\n",
    "        self.conv_block2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2), #64x16x16\n",
    "                                         nn.BatchNorm2d(64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, 2)) #64x8x8\n",
    "        # third convolutional block\n",
    "        self.conv_block3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=256, kernel_size=5, stride=1, padding=2), #256x8x8\n",
    "                                         nn.BatchNorm2d(256),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, 2)) #256x4x4\n",
    "        # fully connected blocks\n",
    "        self.fc1 = nn.Flatten(1)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3))\n",
    "        self.fc4 = nn.Linear(1024, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = LeNet5().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c2aeb",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b31438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(utils_datasets.mnist_mean, utils_datasets.mnist_std)\n",
    "])\n",
    "\n",
    "def denormalize(img, std, mean):\n",
    "    img = img * std\n",
    "    return img + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d28ec",
   "metadata": {},
   "source": [
    "defining the dataset and dataloader from which the data will be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ff13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = utils_datasets.DynamicDMNIST(transform=transform_train, dataset_size=150000)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b0fa0",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN!\n",
    "# put net into train mode\n",
    "net.train()\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78056bbd",
   "metadata": {},
   "source": [
    "### Save/Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b405b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = './res/LeNet5D_5.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c40748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "PATH = './res/LeNet5D_5.pth'\n",
    "net.load_state_dict(torch.load(PATH, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92094da5",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b75490",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32,32)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(utils_datasets.mnist_mean, utils_datasets.mnist_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4311ca1",
   "metadata": {},
   "source": [
    "defining the dataset and dataloader from which the data will be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6445ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = utils_datasets.testMNISTDataset('./data/testDMNIST/', transform_test)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              test_batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560704e",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct prediction\n",
    "correct = 0.0 \n",
    "# total number of prediction\n",
    "total = 0-0\n",
    "# number of correct predition every 10 mini-batches\n",
    "running_accuracy = 0.0\n",
    "\n",
    "# put net into evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # picking the class with the highest value as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # updating the stats\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f'[batch {i + 1:5d}] accuracy: {100 * running_accuracy // (10 * labels.size(0))} %')\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct prediction\n",
    "correct = 0.0 \n",
    "# total number of prediction\n",
    "total = 0.0\n",
    "# number of correct predition every 10 mini-batches\n",
    "running_accuracy = 0.0\n",
    "# total erroneous prediction\n",
    "err = 0\n",
    "# erroneous prediction on one digit numbers\n",
    "unit_err = 0\n",
    "# erroneous prediction on two digit numbers\n",
    "dec_err = 0\n",
    "# erroneous prediction on three digit numbers\n",
    "cent_err = 0\n",
    "# put net into evaluation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # picking the class with the highest value as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # updating the stats\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_accuracy += (predicted == labels).sum().item()\n",
    "        for p, l in zip(predicted, labels):\n",
    "            if p != l:\n",
    "                err += 1\n",
    "                if l < 10:\n",
    "                    unit_err +=1\n",
    "                elif l < 100:\n",
    "                    dec_err +=1\n",
    "                else: \n",
    "                    cent_err +=1\n",
    "                    \n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f'[batch {i + 1:5d}] accuracy: {100 * running_accuracy // (10 * labels.size(0))} %')\n",
    "            print(f'[batch {i + 1:5d}] total error: {err}, unit_err: {unit_err}, dec_err: {dec_err}, cent_err: {cent_err}')\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')\n",
    "print(f'err: {err}, unit_err: {unit_err}, dec_err: {dec_err}, cent_err: {cent_err}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
